{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"titan Prometheus monitoring for shiny applications, plumber APIs, and other R web services. Acknowledgement I have put this package together in order to 1) grasp a better understanding of Prometheus metrics and 2) have some direct control over the source code of software I deploy for clients. I have written and re-written this three times before discovering openmetrics , an R package that provides the same functionalities. I have taken much inspiration from it. Related work There are other packages out there that will let you serve Prometheus metrics. openmetrics provides support for all metrics as well as authentication, and goes a step further in enforcing OpenMetrics standards. pRometheus Provides support for Gauge and Counter.","title":"Home"},{"location":"#titan","text":"Prometheus monitoring for shiny applications, plumber APIs, and other R web services.","title":"titan"},{"location":"#acknowledgement","text":"I have put this package together in order to 1) grasp a better understanding of Prometheus metrics and 2) have some direct control over the source code of software I deploy for clients. I have written and re-written this three times before discovering openmetrics , an R package that provides the same functionalities. I have taken much inspiration from it.","title":"Acknowledgement"},{"location":"#related-work","text":"There are other packages out there that will let you serve Prometheus metrics. openmetrics provides support for all metrics as well as authentication, and goes a step further in enforcing OpenMetrics standards. pRometheus Provides support for Gauge and Counter.","title":"Related work"},{"location":"about/","text":"About Titan & Monitoring Titan is an R package to allow generating Prometheus metrics for R projects, including shiny, plumber, ambiorix, and more. When products rely on plumber APIs and teams rely on shiny applications these better be up and running. These services may crash, become overloaded, their response latency might increase, they may run out of resources, and more. In addition these scale non-linearly as the number of such services or containers grow; hence monitoring their health and being alerted when they raise too many errors or crash becomes crucial. Prometheus is an open-source monitoring and alerting solution. There are other such monitoring tools out there such as Sensu , Nagios , or InfluxDB which also focus on time series data. Push vs. Pull Prometheus differs from other services in many ways but the most important one probably is the fact that it reads the metrics from services from an endpoint provided by said service; it pulls the data. Whereas many other solutions work the other way around; metrics are pushed to the service for monitoring. The latter has the disadvantage that a tiny mistake can result in too much data being pushed to the monitoring service thereby essentially DDoSing yourself. Another difference is that Prometheus is built with containers in mind (Docker & Kubernetes). Though fully open-sourced today, it was initially developed at Soundcloud which is a big advocate of and pioneer in using micro-services at scale. Black box vs. White box Up until recently most monitoring was probably \"black box,\" applications were developed by some people and deployed by others. Devops had to set up monitoring of services with little knowledge of them. Nowadays, with the advent of micro-services where developers are responsible for the deployment of the apps they build, the industry is increasingly turning towards \"white box\" monitoring. You build it you run it -- Jeff Bezos As the developer of the service you know more about it than anyone and can therefore setup more appropriate monitoring; Prometheus and titan let you do just that. This is particularly relevant to R programmers, most of which actually have to deploy the services they build. It's not as daunting as it sounds, it's rather natural, and you quickly come to enjoy it, a bit like testthat in a sense. Scale Monitoring is often mentioned along with large-scale micro-services where it is absolutely necessary. But this is not the only time when monitoring is useful. Surely, as the developer of an application, you want to keep an eye on its performances. Perhaps you were given performance objectives, like reducing the load time of a shiny application or reducing the response time of a plumber API endpoint. Even at a small scale monitoring is interesting and useful. Set up alerts when your services go down and fix them before your boss learns about it via a client.","title":"Monitoring"},{"location":"about/#about-titan-monitoring","text":"Titan is an R package to allow generating Prometheus metrics for R projects, including shiny, plumber, ambiorix, and more. When products rely on plumber APIs and teams rely on shiny applications these better be up and running. These services may crash, become overloaded, their response latency might increase, they may run out of resources, and more. In addition these scale non-linearly as the number of such services or containers grow; hence monitoring their health and being alerted when they raise too many errors or crash becomes crucial. Prometheus is an open-source monitoring and alerting solution. There are other such monitoring tools out there such as Sensu , Nagios , or InfluxDB which also focus on time series data.","title":"About Titan &amp; Monitoring"},{"location":"about/#push-vs-pull","text":"Prometheus differs from other services in many ways but the most important one probably is the fact that it reads the metrics from services from an endpoint provided by said service; it pulls the data. Whereas many other solutions work the other way around; metrics are pushed to the service for monitoring. The latter has the disadvantage that a tiny mistake can result in too much data being pushed to the monitoring service thereby essentially DDoSing yourself. Another difference is that Prometheus is built with containers in mind (Docker & Kubernetes). Though fully open-sourced today, it was initially developed at Soundcloud which is a big advocate of and pioneer in using micro-services at scale.","title":"Push vs. Pull"},{"location":"about/#black-box-vs-white-box","text":"Up until recently most monitoring was probably \"black box,\" applications were developed by some people and deployed by others. Devops had to set up monitoring of services with little knowledge of them. Nowadays, with the advent of micro-services where developers are responsible for the deployment of the apps they build, the industry is increasingly turning towards \"white box\" monitoring. You build it you run it -- Jeff Bezos As the developer of the service you know more about it than anyone and can therefore setup more appropriate monitoring; Prometheus and titan let you do just that. This is particularly relevant to R programmers, most of which actually have to deploy the services they build. It's not as daunting as it sounds, it's rather natural, and you quickly come to enjoy it, a bit like testthat in a sense.","title":"Black box vs. White box"},{"location":"about/#scale","text":"Monitoring is often mentioned along with large-scale micro-services where it is absolutely necessary. But this is not the only time when monitoring is useful. Surely, as the developer of an application, you want to keep an eye on its performances. Perhaps you were given performance objectives, like reducing the load time of a shiny application or reducing the response time of a plumber API endpoint. Even at a small scale monitoring is interesting and useful. Set up alerts when your services go down and fix them before your boss learns about it via a client.","title":"Scale"},{"location":"internals/","text":"Internals This gives some details on the internals of titan that may be of use when using the package. Principle Titan aims not to make your service go down, that would be too ironic. Therefore titan makes very little use of stop and instead uses warning starting in [IGNORING] and skips the action. E.g.: One cannot decrease the value of Counters, if you try to do so Titan will return a warning and ignore the action but will not stop . Storage When titan is loaded in your environment with library(titan) it creates an environment in which it stores all metrics. This is useful when, for instance, you setup a shiny application with titan, run it locally with titanApp , test it, then stop the app to make changes; when you run it again the metrics from the previous run will remain. You can run cleanRegistry to clean the environment. Serving As mentioned Prometheus pulls the metrics from your service, therefore those metrics have to be made available. These are exposed in the form of a plain text ( text/plain ) endpoint called /metrics where titan will serve the metrics that Prometheus can then read, store, and analyse. With shiny you can use the function titanApp where you would normally use shinyApp , with plumber, Ambiorix, and other services you can use renderMetrics . There is more detail and many examples on how to use this on this site.","title":"Internals"},{"location":"internals/#internals","text":"This gives some details on the internals of titan that may be of use when using the package.","title":"Internals"},{"location":"internals/#principle","text":"Titan aims not to make your service go down, that would be too ironic. Therefore titan makes very little use of stop and instead uses warning starting in [IGNORING] and skips the action. E.g.: One cannot decrease the value of Counters, if you try to do so Titan will return a warning and ignore the action but will not stop .","title":"Principle"},{"location":"internals/#storage","text":"When titan is loaded in your environment with library(titan) it creates an environment in which it stores all metrics. This is useful when, for instance, you setup a shiny application with titan, run it locally with titanApp , test it, then stop the app to make changes; when you run it again the metrics from the previous run will remain. You can run cleanRegistry to clean the environment.","title":"Storage"},{"location":"internals/#serving","text":"As mentioned Prometheus pulls the metrics from your service, therefore those metrics have to be made available. These are exposed in the form of a plain text ( text/plain ) endpoint called /metrics where titan will serve the metrics that Prometheus can then read, store, and analyse. With shiny you can use the function titanApp where you would normally use shinyApp , with plumber, Ambiorix, and other services you can use renderMetrics . There is more detail and many examples on how to use this on this site.","title":"Serving"},{"location":"deploy/prometheus/","text":"Prometheus Serving metrics with titan is only part of the story. Once those are served one must set up and deploy Prometheus so it can scrape those results. There are a few ways in which Prometheus can be deployed. The easiest I find is simply to install the binary and run is a service, this way it automatically restarts when the server reboots, etc. Below we download the zipped latest release (at the time of writing this v2.23.0). wget https://github.com/prometheus/prometheus/releases/download/v2.23.0/prometheus-2.23.0.linux-amd64.tar.gz tar xvfz prometheus-2.23.0.linux-amd64.tar.gz mv prometheus-2.23.0.linux-amd64 prometheus This downloads, unzips the files necessary to run Prometheus, then renames the directory from prometheus-2.23.0.linux-amd64 to prometheus . Next you can move into that directory and run Prometheus manually to make sure all works well. cd ./prometheus ./prometheus This should run prometheus and make it available on port 9090 by default and you should be able to see prometheus running at <server-ip>:9090 . If you do not make sure that port 9090 is open on your server. The prometheus.yml file contains the \"targets\" to scrape, that is the plumber APIs and shiny applications to scrape the metrics. We can create a new service to easily have Prometheus run in the background, restart when needed, etc. vi /etc/systemd/system/prometheus.service In that service place the following. [Unit] Description=Prometheus Documentation=https://prometheus.io/docs/introduction/overview/ Wants=network-online.target After=network-online.target [Service] Type=simple User=root ExecReload=/bin/kill -HUP \\$MAINPID ExecStart=/prometheus/prometheus \\ --config.file=/prometheus/prometheus.yml \\ --web.enable-lifecycle SyslogIdentifier=prometheus Restart=always [Install] WantedBy=multi-user.target This essentially will create a new service, very similar to shiny-server. Note the use of --web.enable-lifecycle to reload the configuration file by executing a POST query. This creates the service it can then be run after reloading the daemon. sudo systemctl daemon-reload sudo systemctl start prometheus sudo systemctl enable prometheus Running sudo systemctl status prometheus will show whether the service is running correctly. Configuration file We have yet to explore the configuration file. Below is an example of a job to scrape a shiny application. scrape_configs: - job_name: my-application scheme: 'http' targets: ['shiny-server.com'] metrics_path: 'myapp/metrics' basic_auth: username: titan password: secret2020! - job_name: my-other-application scheme: 'http' targets: ['shiny-server.com'] metrics_path: 'anotherApp/metrics' basic_auth: username: myName password: securePassword Reload Configuration Once changes have been made to the configuration we must tell prometheus to reload it. Since we set the flag --web.enable-lifecycle when launching the Prometheus service we can simply make a POST request to the /-/reload endpoint of Prometheus to reload the configuration file. curl -X POST http://localhost:9090/-/reload There is a convenience function in titan to do so from R. reloadConfig(\"http://localhost:9090\") From there onwards it's just a matter of adding jobs to the configuration file and reload it. Happy tracking!","title":"Prometheus"},{"location":"deploy/prometheus/#prometheus","text":"Serving metrics with titan is only part of the story. Once those are served one must set up and deploy Prometheus so it can scrape those results. There are a few ways in which Prometheus can be deployed. The easiest I find is simply to install the binary and run is a service, this way it automatically restarts when the server reboots, etc. Below we download the zipped latest release (at the time of writing this v2.23.0). wget https://github.com/prometheus/prometheus/releases/download/v2.23.0/prometheus-2.23.0.linux-amd64.tar.gz tar xvfz prometheus-2.23.0.linux-amd64.tar.gz mv prometheus-2.23.0.linux-amd64 prometheus This downloads, unzips the files necessary to run Prometheus, then renames the directory from prometheus-2.23.0.linux-amd64 to prometheus . Next you can move into that directory and run Prometheus manually to make sure all works well. cd ./prometheus ./prometheus This should run prometheus and make it available on port 9090 by default and you should be able to see prometheus running at <server-ip>:9090 . If you do not make sure that port 9090 is open on your server. The prometheus.yml file contains the \"targets\" to scrape, that is the plumber APIs and shiny applications to scrape the metrics. We can create a new service to easily have Prometheus run in the background, restart when needed, etc. vi /etc/systemd/system/prometheus.service In that service place the following. [Unit] Description=Prometheus Documentation=https://prometheus.io/docs/introduction/overview/ Wants=network-online.target After=network-online.target [Service] Type=simple User=root ExecReload=/bin/kill -HUP \\$MAINPID ExecStart=/prometheus/prometheus \\ --config.file=/prometheus/prometheus.yml \\ --web.enable-lifecycle SyslogIdentifier=prometheus Restart=always [Install] WantedBy=multi-user.target This essentially will create a new service, very similar to shiny-server. Note the use of --web.enable-lifecycle to reload the configuration file by executing a POST query. This creates the service it can then be run after reloading the daemon. sudo systemctl daemon-reload sudo systemctl start prometheus sudo systemctl enable prometheus Running sudo systemctl status prometheus will show whether the service is running correctly.","title":"Prometheus"},{"location":"deploy/prometheus/#configuration-file","text":"We have yet to explore the configuration file. Below is an example of a job to scrape a shiny application. scrape_configs: - job_name: my-application scheme: 'http' targets: ['shiny-server.com'] metrics_path: 'myapp/metrics' basic_auth: username: titan password: secret2020! - job_name: my-other-application scheme: 'http' targets: ['shiny-server.com'] metrics_path: 'anotherApp/metrics' basic_auth: username: myName password: securePassword","title":"Configuration file"},{"location":"deploy/prometheus/#reload-configuration","text":"Once changes have been made to the configuration we must tell prometheus to reload it. Since we set the flag --web.enable-lifecycle when launching the Prometheus service we can simply make a POST request to the /-/reload endpoint of Prometheus to reload the configuration file. curl -X POST http://localhost:9090/-/reload There is a convenience function in titan to do so from R. reloadConfig(\"http://localhost:9090\") From there onwards it's just a matter of adding jobs to the configuration file and reload it. Happy tracking!","title":"Reload Configuration"},{"location":"guide/","text":"Get Started First install the R package. Installation Titan is not yet available on CRAN, it can be obtained from Github . remotes You can use the remotes package. # install.packages(\"remotes\") remotes::install_github(\"devOpifex/titan\") pak You can use the pak package. # install.packages(\"pak\") pak::pkg_install(\"devOpifex/titan\") devtools You can use the devtools package. # install.packages(\"devtools\") devtools::install_github(\"devOpifex/titan\")","title":"Installation"},{"location":"guide/#get-started","text":"First install the R package.","title":"Get Started"},{"location":"guide/#installation","text":"Titan is not yet available on CRAN, it can be obtained from Github . remotes You can use the remotes package. # install.packages(\"remotes\") remotes::install_github(\"devOpifex/titan\") pak You can use the pak package. # install.packages(\"pak\") pak::pkg_install(\"devOpifex/titan\") devtools You can use the devtools package. # install.packages(\"devtools\") devtools::install_github(\"devOpifex/titan\")","title":"Installation"},{"location":"guide/ambiorix/","text":"Ambiorix Then again, the metrics themselves and their usage does not differ, only the way the metrics are served. With ambiorix , create a new get method on the /metrics endpoint, and have it return the results of renderMetrics . library(titan) library(ambiorix) # basic counter c <- Counter$new( name = \"visits_total\", help = \"Total visit to the site\", labels = \"path\" ) app <- Ambiorix$new() app$get(\"/\", function(req, res){ c$inc(path = \"/\") res$send(\"Using {titan} with {ambiorix}!\") }) app$get(\"/about\", function(req, res){ c$inc(path = \"/about\") res$send(\"About {titan} and {ambiorix}!\") }) app$get(\"/metrics\", function(req, res){ res$text(renderMetrics()) }) app$start()","title":"Ambiorix"},{"location":"guide/ambiorix/#ambiorix","text":"Then again, the metrics themselves and their usage does not differ, only the way the metrics are served. With ambiorix , create a new get method on the /metrics endpoint, and have it return the results of renderMetrics . library(titan) library(ambiorix) # basic counter c <- Counter$new( name = \"visits_total\", help = \"Total visit to the site\", labels = \"path\" ) app <- Ambiorix$new() app$get(\"/\", function(req, res){ c$inc(path = \"/\") res$send(\"Using {titan} with {ambiorix}!\") }) app$get(\"/about\", function(req, res){ c$inc(path = \"/about\") res$send(\"About {titan} and {ambiorix}!\") }) app$get(\"/metrics\", function(req, res){ res$text(renderMetrics()) }) app$start()","title":"Ambiorix"},{"location":"guide/authentication/","text":"Authentication If you run shiny applications and plumber APIs on a secure server behind a proxy then you probably do not need authentication. If said applications are exposed publicly then you might want to use authentication so that the metrics are not publicly accessible. Prometheus supports basic authentication , by default it does not use any, but optionally a user and password can be specified in the prometheus.yml so that these are used when hitting the /metrics endpoint. This means the endpoint needs to be secured with the same user and password. Securing the endpoint Use the helper function generateBasicAuth to create a token based on a username and password. Note that the function throws a warning: this function should not be left as-is in your application or plumber API. generateBasicAuth( username = \"titan\", password = \"secret2020!\" ) [1] \"Basic dGl0YW46c2VjcmV0MjAyMCE=\" Warning message: Do not deploy or share this Once the authentication token is created it can be used in setAuthentication . The token should not be displayed in the code as in the example below, ideally should be an environment variable or option. library(titan) library(shiny) setAuthentication(\"Basic dGl0YW46c2VjcmV0MjAyMCE=\") ui <- fluidPage( h2(\"Secure endpoint\") ) server <- function(input, output){} titanApp(ui, server, visits = \"visits\") Running the application above then visiting /metrics should display Unauthorized . Indeed, visiting the endpoint from the browser executes a simple GET request that does not feature bear the token: it is unauthorised. One can open a new R session and use the convenience function getMetrics to test the endpoint. The function optionally takes a second argument, the authentication to use. titan::getMetrics( \"http://127.0.0.1:3145/\", auth = \"Basic dGl0YW46c2VjcmV0MjAyMCE=\" ) Response [http://127.0.0.1:3145/metrics] Date: 2020-12-13 10:46 Status: 200 Content-Type: text/plain Size: 81 B # HELP visits Number of visits to the application # TYPE visits counter visits 1 This returns the metrics as it is, unlike via the browser, authenticated. Prometheus Then one can place the username and password in the job configuration. - job_name: my-api basic_auth: username: titan password: secret2020!","title":"Authentication"},{"location":"guide/authentication/#authentication","text":"If you run shiny applications and plumber APIs on a secure server behind a proxy then you probably do not need authentication. If said applications are exposed publicly then you might want to use authentication so that the metrics are not publicly accessible. Prometheus supports basic authentication , by default it does not use any, but optionally a user and password can be specified in the prometheus.yml so that these are used when hitting the /metrics endpoint. This means the endpoint needs to be secured with the same user and password.","title":"Authentication"},{"location":"guide/authentication/#securing-the-endpoint","text":"Use the helper function generateBasicAuth to create a token based on a username and password. Note that the function throws a warning: this function should not be left as-is in your application or plumber API. generateBasicAuth( username = \"titan\", password = \"secret2020!\" ) [1] \"Basic dGl0YW46c2VjcmV0MjAyMCE=\" Warning message: Do not deploy or share this Once the authentication token is created it can be used in setAuthentication . The token should not be displayed in the code as in the example below, ideally should be an environment variable or option. library(titan) library(shiny) setAuthentication(\"Basic dGl0YW46c2VjcmV0MjAyMCE=\") ui <- fluidPage( h2(\"Secure endpoint\") ) server <- function(input, output){} titanApp(ui, server, visits = \"visits\") Running the application above then visiting /metrics should display Unauthorized . Indeed, visiting the endpoint from the browser executes a simple GET request that does not feature bear the token: it is unauthorised. One can open a new R session and use the convenience function getMetrics to test the endpoint. The function optionally takes a second argument, the authentication to use. titan::getMetrics( \"http://127.0.0.1:3145/\", auth = \"Basic dGl0YW46c2VjcmV0MjAyMCE=\" ) Response [http://127.0.0.1:3145/metrics] Date: 2020-12-13 10:46 Status: 200 Content-Type: text/plain Size: 81 B # HELP visits Number of visits to the application # TYPE visits counter visits 1 This returns the metrics as it is, unlike via the browser, authenticated.","title":"Securing the endpoint"},{"location":"guide/authentication/#prometheus","text":"Then one can place the username and password in the job configuration. - job_name: my-api basic_auth: username: titan password: secret2020!","title":"Prometheus"},{"location":"guide/metrics/","text":"Metrics Prometheus provides four types of metrics. This document only briefly explains them, please refer to the official documentation if you need to learn more about it. Note that of the four types the most commonly used are the Counter and Gauge, the Histogram and Summary are extremely useful but used must less as they are most complicated to fully understand and set up correctly. Many client libraries of Prometheus do not even provide support for Histograms and Summaries. Basics Every metrics must bear a unique name and help text. Titan will not let you override a metric: make sure the names (identifiers) are unique. The help text is also mandatory as per Prometheus, it allows giving more context on the metric tracked. Optionally, metrics can also take labels, which will be detailed later in this document. All metrics are R6 classes, you can have any number of these metrics in any project. Counter A counter is the most basic metrics one can use. It consists of a simple counter that can only go up ; the value of counters can never decrease. This can be used to measure the number of times an application is visited, or the number of times an endpoint is hit: these values only ever go up. Never use Counters for values that go down, titan will not let you decrease their value. Instantiate a new counter from the Counter R6 class, give it a name and some help text, then use the method inc to increase it. You can also use the method set to set it to a specific value, again make sure that value is greater than that which the counter already holds or it will throw a warning and not set the counter to that value. c <- Counter$new( name = \"btn_clicks_total\", help = \"Total clicks on buttons\" ) c$inc() # increase c$inc(2) # preview the metrics previewMetrics() # HELP btn_clicks_total Total clicks on buttons # TYPE btn_clicks_total counter btn_clicks_total 3 Gauge A gauge is very similar to the Counter at the exception that its value can decrease . Then again this is set up in similar way as the Counter, the only difference is that it also has a dec method to decrease the gauge. g <- Gauge$new( name = \"current_users_total\", help = \"Total number of users right now\" ) g$inc(2) # increase by 2 g$dec() # decrease by 1 # preview the metrics previewMetrics() # HELP current_users_total Total number of users right now # TYPE current_users_total gauge current_users_total 1 So why would you use a Counter when a Gauge does the same and more? Because this is stored and processed differently by Prometheus. Prometheus is, at its core, a time series database and will take the metric type into account when reporting metrics. Histogram Histograms allow you to count observations and put them in configurable buckets. Start by declaring a predicate; a function which will turn put the observations into buckets. A bucket is defined using the bucket function which takes 1) the label of the bucket, and 2) the value of said bucket. Below we create a predicate that will put the observations into two buckets. It will be used to measure the time it take to process a request, if the request takes more than 3 seconds it goes into a bucket called \"3\" and if it takes over 3 seconds it will put the observation into another bucket called \"9\". # predicate to put observations into buckets. pred <- function(value){ v <- as.numeric(value) # put in bucket 3 if less than 3 seconds if(v < 3) return(bucket(label = \"3\", v)) # otherwise put in bucket 9 bucket(label = \"9\", v) } The creation of the histogram itself differs little from other metrics: specify a unique name, help text, and pass the predicate function previously defined. h <- Histogram$new( name = \"request_process_time\", help = \"Time it took to process the request\", predicate = pred ) Here, to demonstrate, we create a function to simulate a request taking time by randomly making the function sleep for between 1 and 9 seconds. When the function exits we observe the time difference between the beginning and end of the function. The observe method will internally run the predicate and place the results into buckets. simulateRequest <- function(){ # time at which the request starts start <- Sys.time() # when done on.exit({ # compute time difference diff <- Sys.time() - start # observe data # will internally run `pred` h$observe(diff) }) # sleep between 1 and 9 seconds Sys.sleep(sample(1:9, 1)) print(\"done\") } # simulate some requests simulateRequest() simulateRequest() simulateRequest() simulateRequest() # preview the metrics previewMetrics() # HELP request_process_time Time it took to process the request # TYPE request_process_time histogram request_process_time {le=\"3\"} 2 request_process_time {le=\"9\"} 2 request_process_time_count 4 request_process_time_sum 13.0094513893127 Note that the histogram (as per Prometheus standards) also logs the count , the number of observations and the sum the sum of the observations. Above we can see that 4 requests were made that took a total of ~13 seconds; 2 of these took less than 3 seconds and the other 2 took more than that. Summary The Summary metric is very similar to the histogram, and works the same with Titan (predicate, etc.) except it does not count the observations in each buckets, instead it computes the sum of it. Also these buckets in Summary are called quantiles and must be between zero and one (0 < q < 1). Labels Labels allow adding granularity to metrics without duplicating them. From the official documentation : CAUTION: Remember that every unique combination of key-value label pairs represents a new time series, which can dramatically increase the amount of data stored. Do not use labels to store dimensions with high cardinality (many different label values), such as user IDs, email addresses, or other unbounded sets of values. Say for instance you have a small API with three endpoints and simply want to track the number of times they get pinged. Though you could create three separate Counters it might be more convenient to create a simple Counter with a label that can be set to the path that is used. c <- Counter$new( name = \"api_visits_total\", help = \"Total API visits\", labels = \"endpoint\" ) c$inc(1, endpoint = \"/\") c$inc(1, endpoint = \"/count\") c$inc(1, endpoint = \"/home\") c$inc(2, endpoint = \"/home\") previewMetrics() # HELP api_visits_total Total API visits # TYPE api_visits_total counter api_visits_total {endpoint=\"/\"} 1 api_visits_total {endpoint=\"/count\"} 1 api_visits_total {endpoint=\"/home\"} 3 If you use labels you must specify all of the labels every time you change the value of the metric ( inc , dec , set , observe ). Otherwise titan throws a warning and ignores the action.","title":"Metrics"},{"location":"guide/metrics/#metrics","text":"Prometheus provides four types of metrics. This document only briefly explains them, please refer to the official documentation if you need to learn more about it. Note that of the four types the most commonly used are the Counter and Gauge, the Histogram and Summary are extremely useful but used must less as they are most complicated to fully understand and set up correctly. Many client libraries of Prometheus do not even provide support for Histograms and Summaries.","title":"Metrics"},{"location":"guide/metrics/#basics","text":"Every metrics must bear a unique name and help text. Titan will not let you override a metric: make sure the names (identifiers) are unique. The help text is also mandatory as per Prometheus, it allows giving more context on the metric tracked. Optionally, metrics can also take labels, which will be detailed later in this document. All metrics are R6 classes, you can have any number of these metrics in any project.","title":"Basics"},{"location":"guide/metrics/#counter","text":"A counter is the most basic metrics one can use. It consists of a simple counter that can only go up ; the value of counters can never decrease. This can be used to measure the number of times an application is visited, or the number of times an endpoint is hit: these values only ever go up. Never use Counters for values that go down, titan will not let you decrease their value. Instantiate a new counter from the Counter R6 class, give it a name and some help text, then use the method inc to increase it. You can also use the method set to set it to a specific value, again make sure that value is greater than that which the counter already holds or it will throw a warning and not set the counter to that value. c <- Counter$new( name = \"btn_clicks_total\", help = \"Total clicks on buttons\" ) c$inc() # increase c$inc(2) # preview the metrics previewMetrics() # HELP btn_clicks_total Total clicks on buttons # TYPE btn_clicks_total counter btn_clicks_total 3","title":"Counter"},{"location":"guide/metrics/#gauge","text":"A gauge is very similar to the Counter at the exception that its value can decrease . Then again this is set up in similar way as the Counter, the only difference is that it also has a dec method to decrease the gauge. g <- Gauge$new( name = \"current_users_total\", help = \"Total number of users right now\" ) g$inc(2) # increase by 2 g$dec() # decrease by 1 # preview the metrics previewMetrics() # HELP current_users_total Total number of users right now # TYPE current_users_total gauge current_users_total 1 So why would you use a Counter when a Gauge does the same and more? Because this is stored and processed differently by Prometheus. Prometheus is, at its core, a time series database and will take the metric type into account when reporting metrics.","title":"Gauge"},{"location":"guide/metrics/#histogram","text":"Histograms allow you to count observations and put them in configurable buckets. Start by declaring a predicate; a function which will turn put the observations into buckets. A bucket is defined using the bucket function which takes 1) the label of the bucket, and 2) the value of said bucket. Below we create a predicate that will put the observations into two buckets. It will be used to measure the time it take to process a request, if the request takes more than 3 seconds it goes into a bucket called \"3\" and if it takes over 3 seconds it will put the observation into another bucket called \"9\". # predicate to put observations into buckets. pred <- function(value){ v <- as.numeric(value) # put in bucket 3 if less than 3 seconds if(v < 3) return(bucket(label = \"3\", v)) # otherwise put in bucket 9 bucket(label = \"9\", v) } The creation of the histogram itself differs little from other metrics: specify a unique name, help text, and pass the predicate function previously defined. h <- Histogram$new( name = \"request_process_time\", help = \"Time it took to process the request\", predicate = pred ) Here, to demonstrate, we create a function to simulate a request taking time by randomly making the function sleep for between 1 and 9 seconds. When the function exits we observe the time difference between the beginning and end of the function. The observe method will internally run the predicate and place the results into buckets. simulateRequest <- function(){ # time at which the request starts start <- Sys.time() # when done on.exit({ # compute time difference diff <- Sys.time() - start # observe data # will internally run `pred` h$observe(diff) }) # sleep between 1 and 9 seconds Sys.sleep(sample(1:9, 1)) print(\"done\") } # simulate some requests simulateRequest() simulateRequest() simulateRequest() simulateRequest() # preview the metrics previewMetrics() # HELP request_process_time Time it took to process the request # TYPE request_process_time histogram request_process_time {le=\"3\"} 2 request_process_time {le=\"9\"} 2 request_process_time_count 4 request_process_time_sum 13.0094513893127 Note that the histogram (as per Prometheus standards) also logs the count , the number of observations and the sum the sum of the observations. Above we can see that 4 requests were made that took a total of ~13 seconds; 2 of these took less than 3 seconds and the other 2 took more than that.","title":"Histogram"},{"location":"guide/metrics/#summary","text":"The Summary metric is very similar to the histogram, and works the same with Titan (predicate, etc.) except it does not count the observations in each buckets, instead it computes the sum of it. Also these buckets in Summary are called quantiles and must be between zero and one (0 < q < 1).","title":"Summary"},{"location":"guide/metrics/#labels","text":"Labels allow adding granularity to metrics without duplicating them. From the official documentation : CAUTION: Remember that every unique combination of key-value label pairs represents a new time series, which can dramatically increase the amount of data stored. Do not use labels to store dimensions with high cardinality (many different label values), such as user IDs, email addresses, or other unbounded sets of values. Say for instance you have a small API with three endpoints and simply want to track the number of times they get pinged. Though you could create three separate Counters it might be more convenient to create a simple Counter with a label that can be set to the path that is used. c <- Counter$new( name = \"api_visits_total\", help = \"Total API visits\", labels = \"endpoint\" ) c$inc(1, endpoint = \"/\") c$inc(1, endpoint = \"/count\") c$inc(1, endpoint = \"/home\") c$inc(2, endpoint = \"/home\") previewMetrics() # HELP api_visits_total Total API visits # TYPE api_visits_total counter api_visits_total {endpoint=\"/\"} 1 api_visits_total {endpoint=\"/count\"} 1 api_visits_total {endpoint=\"/home\"} 3 If you use labels you must specify all of the labels every time you change the value of the metric ( inc , dec , set , observe ). Otherwise titan throws a warning and ignores the action.","title":"Labels"},{"location":"guide/plumber/","text":"Plumber APIs The metrics and how they are used never changes, the only thing that changes across projects is how the metrics are served. Create the plumber API as you normally would. #* Increment a counter #* @get / function() { return(\"Hello titan!\") } #* Plot a histogram #* @serializer png #* @get /plot function() { rand <- rnorm(100) hist(rand) } Then use the function prTitan as you would normally use pr . This example here will serve the metrics but none are currently tracked. library(plumber) titan::prTitan(\"file.R\") %>% pr_run() As with shiny, titan provides an out-of-the-box metric to track: latency . As with shiny ( titanApp ), the latency argument defaults to NULL meaning this is not being tracked, to turn on that tracking pass it a character string: the name of the metric. Latency tracks the time it takes for the API to serve requests. This is tracked with a Histogram that uses predefined bucket s that put the request time in milliseconds in various bins (e.g.: 300 milliseconds, 600 milliseconds, etc.). It also uses some labels to track: The method used for the request, e.g.: GET or POST . The path of the request, e.g.: /plot . The status of the request, e.g.: 200 or 404 . library(plumber) titan::prTitan(\"file.R\", latency = \"latency\") %>% pr_run()","title":"Plumber"},{"location":"guide/plumber/#plumber-apis","text":"The metrics and how they are used never changes, the only thing that changes across projects is how the metrics are served. Create the plumber API as you normally would. #* Increment a counter #* @get / function() { return(\"Hello titan!\") } #* Plot a histogram #* @serializer png #* @get /plot function() { rand <- rnorm(100) hist(rand) } Then use the function prTitan as you would normally use pr . This example here will serve the metrics but none are currently tracked. library(plumber) titan::prTitan(\"file.R\") %>% pr_run() As with shiny, titan provides an out-of-the-box metric to track: latency . As with shiny ( titanApp ), the latency argument defaults to NULL meaning this is not being tracked, to turn on that tracking pass it a character string: the name of the metric. Latency tracks the time it takes for the API to serve requests. This is tracked with a Histogram that uses predefined bucket s that put the request time in milliseconds in various bins (e.g.: 300 milliseconds, 600 milliseconds, etc.). It also uses some labels to track: The method used for the request, e.g.: GET or POST . The path of the request, e.g.: /plot . The status of the request, e.g.: 200 or 404 . library(plumber) titan::prTitan(\"file.R\", latency = \"latency\") %>% pr_run()","title":"Plumber APIs"},{"location":"guide/shiny/","text":"Shiny Basics In this wee vignette we give just basic examples of how to use titan in shiny applications. Helpers Titan allows easily tracking some interactions by default, saving you the trouble of setting up metrics. Starting from the (very) basic shiny application below which simply prints text to the console at the click of a button. library(shiny) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { cat(\"Logging one click\\n\") }) } shinyApp(ui, server) We will see how to define custom metrics later but before we do so, there are a number out-of-the-box (optional) metrics that titan provides: Inputs: Tracks all input messages sent from the front-end to the server to better understand which are most used. This is handled with a counter that uses the name of the inputs as labels . Visits: Tracks the total number of visits to the shiny application with a counter. Concurrent: Tracks the number of concurrent users currently on the application with a gauge. Duration: Tracks the session duration; the time (in seconds) users stay and interact with the application. As mentioned, all of those are optional (off by default) but whether you use the defaults presented here and/or your custom metrics you must use titanApp to launch the application. This function takes the same inputs as shinyApp and more. The arguments inputs , visits , concurrent , and duration , which all default to NULL meaning they are not being tracked. To track those metrics one must pass it a character string defining the name of the metric. library(shiny) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { cat(\"Logging one click\\n\") }) } # use titanApp titanApp( ui, server, inputs = \"inputs\", visits = \"visits\", concurrent = \"concurrent\", duration = \"duration\" ) Counter Let's use titan to track the number of clicks on this button rather than use the defaults provided by titan. We can use a counter since the number of clicks can only increase over time. Load the titan package then create the counter. Note that it is created outside the application, as it only needs to be created once, placing it in the server would recreate it every time. Though this should not be an issue as titan prevents you from overwriting an already created counter it is best to avoid it. In the observer we increment the counter, then note that we launch the application with titanApp and not shinyApp , it works the exact same way but exposes the metrics. library(titan) library(shiny) # create the counter c <- Counter$new( name = \"btn_click_total\", help = \"Number of clicks of the button\" ) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { c$inc() cat(\"Logging one click\\n\") }) } # use titanApp titanApp(ui, server) Histogram We can also use a histogram to track the performances of a particularly long request. Say for instance, that the application, at the click of a button, makes a relatively large request to a database or runs a time consuming model, surely we'd like to track that. We can build a histogram to track the time it takes to run that process. We'll use the histogram to put the time it takes into three bins: Less than 3 seconds Between 3 and 6 seconds 6 Seconds and more library(titan) library(shiny) classify <- function(value){ v <- as.numeric(value) if(v < 3) return(bucket(\"0-3\", v)) else if (v > 3 && v < 6) return(bucket(\"3-6\", v)) else return(bucket(\"9\", v)) } hist <- Histogram$new( \"process_time\", \"Lengthy process timing\", predicate = classify ) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { start <- Sys.time() on.exit({ diff <- Sys.time() - start hist$observe(diff) }) Sys.sleep(sample(1:9, 1)) cat(\"Done with process\\n\") }) } titanApp(ui, server) Gauge You could also create a gauge to track the current number of visitors on the application using a Gauge. It's as simple as initialising the Gauge and increasing it by one every time the server fires. library(shiny) g <- Gauge$new( \"visitors_total\", \"Current number of visitors\" ) ui <- fluidPage( h1(\"Hello\") ) server <- function(input, output){ g$inc() } titanApp(ui, server)","title":"Shiny"},{"location":"guide/shiny/#shiny-basics","text":"In this wee vignette we give just basic examples of how to use titan in shiny applications.","title":"Shiny Basics"},{"location":"guide/shiny/#helpers","text":"Titan allows easily tracking some interactions by default, saving you the trouble of setting up metrics. Starting from the (very) basic shiny application below which simply prints text to the console at the click of a button. library(shiny) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { cat(\"Logging one click\\n\") }) } shinyApp(ui, server) We will see how to define custom metrics later but before we do so, there are a number out-of-the-box (optional) metrics that titan provides: Inputs: Tracks all input messages sent from the front-end to the server to better understand which are most used. This is handled with a counter that uses the name of the inputs as labels . Visits: Tracks the total number of visits to the shiny application with a counter. Concurrent: Tracks the number of concurrent users currently on the application with a gauge. Duration: Tracks the session duration; the time (in seconds) users stay and interact with the application. As mentioned, all of those are optional (off by default) but whether you use the defaults presented here and/or your custom metrics you must use titanApp to launch the application. This function takes the same inputs as shinyApp and more. The arguments inputs , visits , concurrent , and duration , which all default to NULL meaning they are not being tracked. To track those metrics one must pass it a character string defining the name of the metric. library(shiny) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { cat(\"Logging one click\\n\") }) } # use titanApp titanApp( ui, server, inputs = \"inputs\", visits = \"visits\", concurrent = \"concurrent\", duration = \"duration\" )","title":"Helpers"},{"location":"guide/shiny/#counter","text":"Let's use titan to track the number of clicks on this button rather than use the defaults provided by titan. We can use a counter since the number of clicks can only increase over time. Load the titan package then create the counter. Note that it is created outside the application, as it only needs to be created once, placing it in the server would recreate it every time. Though this should not be an issue as titan prevents you from overwriting an already created counter it is best to avoid it. In the observer we increment the counter, then note that we launch the application with titanApp and not shinyApp , it works the exact same way but exposes the metrics. library(titan) library(shiny) # create the counter c <- Counter$new( name = \"btn_click_total\", help = \"Number of clicks of the button\" ) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { c$inc() cat(\"Logging one click\\n\") }) } # use titanApp titanApp(ui, server)","title":"Counter"},{"location":"guide/shiny/#histogram","text":"We can also use a histogram to track the performances of a particularly long request. Say for instance, that the application, at the click of a button, makes a relatively large request to a database or runs a time consuming model, surely we'd like to track that. We can build a histogram to track the time it takes to run that process. We'll use the histogram to put the time it takes into three bins: Less than 3 seconds Between 3 and 6 seconds 6 Seconds and more library(titan) library(shiny) classify <- function(value){ v <- as.numeric(value) if(v < 3) return(bucket(\"0-3\", v)) else if (v > 3 && v < 6) return(bucket(\"3-6\", v)) else return(bucket(\"9\", v)) } hist <- Histogram$new( \"process_time\", \"Lengthy process timing\", predicate = classify ) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { start <- Sys.time() on.exit({ diff <- Sys.time() - start hist$observe(diff) }) Sys.sleep(sample(1:9, 1)) cat(\"Done with process\\n\") }) } titanApp(ui, server)","title":"Histogram"},{"location":"guide/shiny/#gauge","text":"You could also create a gauge to track the current number of visitors on the application using a Gauge. It's as simple as initialising the Gauge and increasing it by one every time the server fires. library(shiny) g <- Gauge$new( \"visitors_total\", \"Current number of visitors\" ) ui <- fluidPage( h1(\"Hello\") ) server <- function(input, output){ g$inc() } titanApp(ui, server)","title":"Gauge"},{"location":"meta/changelog/","text":"titan 2.0.0 Rewritten the entire source code, much cleaner and more performant. titan 1.0.0 Initial version.","title":"Changelog"},{"location":"meta/changelog/#titan-200","text":"Rewritten the entire source code, much cleaner and more performant.","title":"titan 2.0.0"},{"location":"meta/changelog/#titan-100","text":"Initial version.","title":"titan 1.0.0"},{"location":"meta/contribute/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https:// www.contributor-covenant.org/translations.","title":"Contribute"},{"location":"meta/contribute/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"meta/contribute/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"meta/contribute/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"meta/contribute/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"meta/contribute/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"meta/contribute/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at [INSERT CONTACT METHOD]. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"meta/contribute/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"meta/contribute/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"meta/contribute/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"meta/contribute/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"meta/contribute/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"meta/contribute/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https:// www.contributor-covenant.org/translations.","title":"Attribution"}]}