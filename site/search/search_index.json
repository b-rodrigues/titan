{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"titan Prometheus monitoring for shiny applications, plumber APIs, and other R web services. Installation Titan is not yet available on CRAN, it can be obtained from Github . remotes You can use the remotes package. # install.packages(\"remotes\") remotes::install_github(\"devOpifex/titan\") pak You can use the pak package. # install.packages(\"pak\") pak::pkg_install(\"devOpifex/titan\") devtools You can use the devtools package. # install.packages(\"devtools\") devtools::install_github(\"devOpifex/titan\")","title":"Home"},{"location":"#titan","text":"Prometheus monitoring for shiny applications, plumber APIs, and other R web services.","title":"titan"},{"location":"#installation","text":"Titan is not yet available on CRAN, it can be obtained from Github . remotes You can use the remotes package. # install.packages(\"remotes\") remotes::install_github(\"devOpifex/titan\") pak You can use the pak package. # install.packages(\"pak\") pak::pkg_install(\"devOpifex/titan\") devtools You can use the devtools package. # install.packages(\"devtools\") devtools::install_github(\"devOpifex/titan\")","title":"Installation"},{"location":"about/","text":"About Titan & Monitoring Titan is an R package to allow generating Prometheus for R projects, including shiny, plumber, ambiorix, and more. While monitoring is probably not necessary for a single shiny application or plumber services, it becomes crucial as your infrastructure grows. When products rely on plumber APIs and teams rely on shiny applications these better be up and running. These services can simply run into issues, become overloaded, their response latency might increase, they may run out of resources, and more. In addition these scale non-linearly as the number of such services or containers grow; hence monitoring their health and being alerted when they raise too many errors or crash becomes crucial. Prometheus is an open-source monitoring and alerting solution. There are other such monitoring tools out there such as Sensu , Nagios , or InfluxDB which also focus on time series data. Prometheus differs from other services in many ways but the most important one probably is the fact that it reads the metrics from services from an endpoint provided by said service; it pulls the data. Whereas other solutions work the other way around; metrics are pushed to the service for monitoring. The latter has the disadvantage that a tiny mistake can result in too much data being pushed to the monitoring service thereby DDoSing yourself. Another difference is that Prometheus is built with containers in mind (Docker & Kubernetes). Though fully open-sourced today, it was initially developed at Soundcloud which is a big advocate and pioneer in using micro-services at scale. Titan allows creating metrics and their endpoints for Prometheus to scrape and monitor. Black box vs. White box Up until recently most monitoring was probably \"black box,\" applications were developed by some people and deployed by others. Devops had to set up monitoring of services with little knowledge of them. Nowadays, with the advent of micro-services where developers are responsible for the deployment of the apps they build, the industry is increasingly turning towards \"white box\" monitoring. You build it you run it --- Jeff Bezos As the developer of the service you know more about it than anyone and can therefore setup more appropriate monitoring; Prometheus and titan let you do just that. This is particularly relevant to R programmers, most of which actually have to deploy the services they build. It's not as daunting as it sounds, it's rather natural, and you quickly enjoy it, a bit like testthat in a sense. Scale Monitoring is often mentioned along with large-scale micro-services where it is absolutely necessary. But this is not the only time when monitoring is useful. Surely, as the developer of an application, you want to keep an eye on its performances. Perhaps you were given performance objectives, like reducing the load time of a shiny application or reducing the response time of a plumber API endpoint. Even at a small scale monitoring is interesting and useful. Set up alerts when your services go down and fix them before your boss learns about it from a client.","title":"About"},{"location":"about/#about-titan-monitoring","text":"Titan is an R package to allow generating Prometheus for R projects, including shiny, plumber, ambiorix, and more. While monitoring is probably not necessary for a single shiny application or plumber services, it becomes crucial as your infrastructure grows. When products rely on plumber APIs and teams rely on shiny applications these better be up and running. These services can simply run into issues, become overloaded, their response latency might increase, they may run out of resources, and more. In addition these scale non-linearly as the number of such services or containers grow; hence monitoring their health and being alerted when they raise too many errors or crash becomes crucial. Prometheus is an open-source monitoring and alerting solution. There are other such monitoring tools out there such as Sensu , Nagios , or InfluxDB which also focus on time series data. Prometheus differs from other services in many ways but the most important one probably is the fact that it reads the metrics from services from an endpoint provided by said service; it pulls the data. Whereas other solutions work the other way around; metrics are pushed to the service for monitoring. The latter has the disadvantage that a tiny mistake can result in too much data being pushed to the monitoring service thereby DDoSing yourself. Another difference is that Prometheus is built with containers in mind (Docker & Kubernetes). Though fully open-sourced today, it was initially developed at Soundcloud which is a big advocate and pioneer in using micro-services at scale. Titan allows creating metrics and their endpoints for Prometheus to scrape and monitor.","title":"About Titan &amp; Monitoring"},{"location":"about/#black-box-vs-white-box","text":"Up until recently most monitoring was probably \"black box,\" applications were developed by some people and deployed by others. Devops had to set up monitoring of services with little knowledge of them. Nowadays, with the advent of micro-services where developers are responsible for the deployment of the apps they build, the industry is increasingly turning towards \"white box\" monitoring. You build it you run it --- Jeff Bezos As the developer of the service you know more about it than anyone and can therefore setup more appropriate monitoring; Prometheus and titan let you do just that. This is particularly relevant to R programmers, most of which actually have to deploy the services they build. It's not as daunting as it sounds, it's rather natural, and you quickly enjoy it, a bit like testthat in a sense.","title":"Black box vs. White box"},{"location":"about/#scale","text":"Monitoring is often mentioned along with large-scale micro-services where it is absolutely necessary. But this is not the only time when monitoring is useful. Surely, as the developer of an application, you want to keep an eye on its performances. Perhaps you were given performance objectives, like reducing the load time of a shiny application or reducing the response time of a plumber API endpoint. Even at a small scale monitoring is interesting and useful. Set up alerts when your services go down and fix them before your boss learns about it from a client.","title":"Scale"},{"location":"internals/","text":"Internals This gives some details on the internals of titan that may be of use when using the package. Principle Titan aims not to make your service go down, that would be too ironic. Therefore titan makes very little use of stop and instead uses warning and skips errors. E.g.: One cannot decrease the value of Counters, if you try to do so Titan will return a warning and ignore the action but will not stop . Storage When titan is loaded in your environment with library(titan) it creates an environment in which it stores all metrics. This is useful when, for instance, you setup a shiny application with titan, run it locally with titanApp , test it, then stop the app to make changes; when you run it again the metrics from the previous run will remain. You can run resetTitan to clean the environment. Serving As mentioned Prometheus pulls the metrics from your service, therefore those metrics have to be made available. These are exposed in the form of a plain text ( text/plain ) endpoint called /metrics where titan will serve the metrics that Prometheus can then read, store, and analyse. With shiny you can use the function titanApp where you would normally use shinyApp , with plumber, Ambiorix, and other services you can use renderMetrics . There is more detail and many examples on how to use this on this site.","title":"Internals"},{"location":"internals/#internals","text":"This gives some details on the internals of titan that may be of use when using the package.","title":"Internals"},{"location":"internals/#principle","text":"Titan aims not to make your service go down, that would be too ironic. Therefore titan makes very little use of stop and instead uses warning and skips errors. E.g.: One cannot decrease the value of Counters, if you try to do so Titan will return a warning and ignore the action but will not stop .","title":"Principle"},{"location":"internals/#storage","text":"When titan is loaded in your environment with library(titan) it creates an environment in which it stores all metrics. This is useful when, for instance, you setup a shiny application with titan, run it locally with titanApp , test it, then stop the app to make changes; when you run it again the metrics from the previous run will remain. You can run resetTitan to clean the environment.","title":"Storage"},{"location":"internals/#serving","text":"As mentioned Prometheus pulls the metrics from your service, therefore those metrics have to be made available. These are exposed in the form of a plain text ( text/plain ) endpoint called /metrics where titan will serve the metrics that Prometheus can then read, store, and analyse. With shiny you can use the function titanApp where you would normally use shinyApp , with plumber, Ambiorix, and other services you can use renderMetrics . There is more detail and many examples on how to use this on this site.","title":"Serving"},{"location":"guide/","text":"Get Started First install the R package. Installation Titan is not yet available on CRAN, it can be obtained from Github . remotes You can use the remotes package. # install.packages(\"remotes\") remotes::install_github(\"devOpifex/titan\") pak You can use the pak package. # install.packages(\"pak\") pak::pkg_install(\"devOpifex/titan\") devtools You can use the devtools package. # install.packages(\"devtools\") devtools::install_github(\"devOpifex/titan\")","title":"Installation"},{"location":"guide/#get-started","text":"First install the R package.","title":"Get Started"},{"location":"guide/#installation","text":"Titan is not yet available on CRAN, it can be obtained from Github . remotes You can use the remotes package. # install.packages(\"remotes\") remotes::install_github(\"devOpifex/titan\") pak You can use the pak package. # install.packages(\"pak\") pak::pkg_install(\"devOpifex/titan\") devtools You can use the devtools package. # install.packages(\"devtools\") devtools::install_github(\"devOpifex/titan\")","title":"Installation"},{"location":"guide/metrics/","text":"Metrics Prometheus provides four types of metrics. This document only briefly explains them, please refer to the official documentation if you need to learn more about it. Note that of the four types the most commonly used are the Counter and Gauge, the Histogram and Summary are extremely useful but used must less as they are most complicated to fully understand and set up correctly. Many client libraries of Prometheus do not even provide support for Histograms and Summaries. Basics Every metrics must bear a unique name and help text. Titan will not let you override a metric: make sure the names (identifiers) are unique. The help text is also mandatory as per Prometheus, it allows giving more context on the metric tracked. Optionally, metrics can also take labels, which will be detailed later in this document. All metrics are R6 classes, you can have any number of these metrics in any project. Counter A counter is the most basic metrics one can use. It consists of a simple counter that can only go up ; the value of counters can never decrease. This can be used to measure the number of times an application is visited, or the number of times an endpoint is hit: these values only ever go up. Never use Counters for values that go down, titan will not let you decrease their value. Instantiate a new counter from the Counter R6 class, give it a name and some help text, then use the method inc to increase it. You can also use the method set to set it to a specific value, again make sure that value is greater than that which the counter already holds or it will throw a warning and not set the counter to that value. c <- Counter$new( name = \"btn_clicks_total\", help = \"Total clicks on buttons\" ) c$inc() # increase c$inc(2) # preview the metrics previewMetrics() # HELP btn_clicks_total Total clicks on buttons # TYPE btn_clicks_total counter btn_clicks_total 3 Gauge A gauge is very similar to the Counter at the exception that its value can decrease . Then again this is set up in similar way as the Counter, the only difference is that it also has a dec method to decrease the gauge. g <- Gauge$new( name = \"current_users_total\", help = \"Total number of users right now\" ) g$inc(2) # increase by 2 g$dec() # decrease by 1 # preview the metrics previewMetrics() # HELP current_users_total Total number of users right now # TYPE current_users_total gauge current_users_total 1 So why would you use a Counter when a Gauge does the same and more? Because this is stored and processed differently by Prometheus. Prometheus is, at its core, a time series database and will take the metric type into account when reporting metrics. Histogram Histograms allow you to count observations and put them in configurable buckets. Start by declaring a predicate; a function which will turn put the observations into buckets. A bucket is defined using the bucket function which takes 1) the label of the bucket, and 2) the value of said bucket. Below we create a predicate that will put the observations into two buckets. It will be used to measure the time it take to process a request, if the request takes more than 3 seconds it goes into a bucket called \"3\" and if it takes over 3 seconds it will put the observation into another bucket called \"9\". # predicate to put observations into buckets. pred <- function(value){ v <- as.numeric(value) # put in bucket 3 if less than 3 seconds if(v < 3) return(bucket(label = \"3\", v)) # otherwise put in bucket 9 bucket(label = \"9\", v) } The creation of the histogram itself differs little from other metrics: specify a unique name, help text, and pass the predicate function previously defined. h <- Histogram$new( name = \"request_process_time\", help = \"Time it took to process the request\", predicate = pred ) Here, to demonstrate, we create a function to simulate a request taking time by randomly making the function sleep for between 1 and 9 seconds. When the function exits we observe the time difference between the beginning and end of the function. The observe method will internally run the predicate and place the results into buckets. simulateRequest <- function(){ # time at which the request starts start <- Sys.time() # when done on.exit({ # compute time difference diff <- Sys.time() - start # observe data # will internally run `pred` h$observe(diff) }) # sleep between 1 and 9 seconds Sys.sleep(sample(1:9, 1)) print(\"done\") } # simulate some requests simulateRequest() simulateRequest() simulateRequest() simulateRequest() # preview the metrics previewMetrics() # HELP request_process_time Time it took to process the request # TYPE request_process_time histogram request_process_time {le=\"3\"} 2 request_process_time {le=\"9\"} 2 request_process_time_count 4 request_process_time_sum 13.0094513893127 Note that the histogram (as per Prometheus standards) also logs the count , the number of observations and the sum the sum of the observations. Above we can see that 4 requests were made that took a total of ~13 seconds; 2 of these took less than 3 seconds and the other 2 took more than that. Summary The Summary metric is very similar to the histogram, and works the same with Titan (predicate, etc.) except it does not count the observations in each buckets, instead it computes the sum of it. Also these buckets in Summary are called quantiles and must be between zero and one (0 < q < 1). Labels Labels allow adding granularity to metrics without duplicating them. From the official documentation : CAUTION: Remember that every unique combination of key-value label pairs represents a new time series, which can dramatically increase the amount of data stored. Do not use labels to store dimensions with high cardinality (many different label values), such as user IDs, email addresses, or other unbounded sets of values. Say for instance you have a small API with three endpoints and simply want to track the number of times they get pinged. Though you could create three separate Counters it might be more convenient to create a simple Counter with a label that can be set to the path that is used. c <- Counter$new( name = \"api_visits_total\", help = \"Total API visits\", labels = \"endpoint\" ) c$inc(1, endpoint = \"/\") c$inc(1, endpoint = \"/count\") c$inc(1, endpoint = \"/home\") c$inc(2, endpoint = \"/home\") previewMetrics() # HELP api_visits_total Total API visits # TYPE api_visits_total counter api_visits_total {endpoint=\"/\"} 1 api_visits_total {endpoint=\"/count\"} 1 api_visits_total {endpoint=\"/home\"} 3 If you use labels you must specify all of the labels every time you change the value of the metric ( inc , dec , set , observe ). Otherwise titan throws a warning and ignores the action.","title":"Metrics"},{"location":"guide/metrics/#metrics","text":"Prometheus provides four types of metrics. This document only briefly explains them, please refer to the official documentation if you need to learn more about it. Note that of the four types the most commonly used are the Counter and Gauge, the Histogram and Summary are extremely useful but used must less as they are most complicated to fully understand and set up correctly. Many client libraries of Prometheus do not even provide support for Histograms and Summaries.","title":"Metrics"},{"location":"guide/metrics/#basics","text":"Every metrics must bear a unique name and help text. Titan will not let you override a metric: make sure the names (identifiers) are unique. The help text is also mandatory as per Prometheus, it allows giving more context on the metric tracked. Optionally, metrics can also take labels, which will be detailed later in this document. All metrics are R6 classes, you can have any number of these metrics in any project.","title":"Basics"},{"location":"guide/metrics/#counter","text":"A counter is the most basic metrics one can use. It consists of a simple counter that can only go up ; the value of counters can never decrease. This can be used to measure the number of times an application is visited, or the number of times an endpoint is hit: these values only ever go up. Never use Counters for values that go down, titan will not let you decrease their value. Instantiate a new counter from the Counter R6 class, give it a name and some help text, then use the method inc to increase it. You can also use the method set to set it to a specific value, again make sure that value is greater than that which the counter already holds or it will throw a warning and not set the counter to that value. c <- Counter$new( name = \"btn_clicks_total\", help = \"Total clicks on buttons\" ) c$inc() # increase c$inc(2) # preview the metrics previewMetrics() # HELP btn_clicks_total Total clicks on buttons # TYPE btn_clicks_total counter btn_clicks_total 3","title":"Counter"},{"location":"guide/metrics/#gauge","text":"A gauge is very similar to the Counter at the exception that its value can decrease . Then again this is set up in similar way as the Counter, the only difference is that it also has a dec method to decrease the gauge. g <- Gauge$new( name = \"current_users_total\", help = \"Total number of users right now\" ) g$inc(2) # increase by 2 g$dec() # decrease by 1 # preview the metrics previewMetrics() # HELP current_users_total Total number of users right now # TYPE current_users_total gauge current_users_total 1 So why would you use a Counter when a Gauge does the same and more? Because this is stored and processed differently by Prometheus. Prometheus is, at its core, a time series database and will take the metric type into account when reporting metrics.","title":"Gauge"},{"location":"guide/metrics/#histogram","text":"Histograms allow you to count observations and put them in configurable buckets. Start by declaring a predicate; a function which will turn put the observations into buckets. A bucket is defined using the bucket function which takes 1) the label of the bucket, and 2) the value of said bucket. Below we create a predicate that will put the observations into two buckets. It will be used to measure the time it take to process a request, if the request takes more than 3 seconds it goes into a bucket called \"3\" and if it takes over 3 seconds it will put the observation into another bucket called \"9\". # predicate to put observations into buckets. pred <- function(value){ v <- as.numeric(value) # put in bucket 3 if less than 3 seconds if(v < 3) return(bucket(label = \"3\", v)) # otherwise put in bucket 9 bucket(label = \"9\", v) } The creation of the histogram itself differs little from other metrics: specify a unique name, help text, and pass the predicate function previously defined. h <- Histogram$new( name = \"request_process_time\", help = \"Time it took to process the request\", predicate = pred ) Here, to demonstrate, we create a function to simulate a request taking time by randomly making the function sleep for between 1 and 9 seconds. When the function exits we observe the time difference between the beginning and end of the function. The observe method will internally run the predicate and place the results into buckets. simulateRequest <- function(){ # time at which the request starts start <- Sys.time() # when done on.exit({ # compute time difference diff <- Sys.time() - start # observe data # will internally run `pred` h$observe(diff) }) # sleep between 1 and 9 seconds Sys.sleep(sample(1:9, 1)) print(\"done\") } # simulate some requests simulateRequest() simulateRequest() simulateRequest() simulateRequest() # preview the metrics previewMetrics() # HELP request_process_time Time it took to process the request # TYPE request_process_time histogram request_process_time {le=\"3\"} 2 request_process_time {le=\"9\"} 2 request_process_time_count 4 request_process_time_sum 13.0094513893127 Note that the histogram (as per Prometheus standards) also logs the count , the number of observations and the sum the sum of the observations. Above we can see that 4 requests were made that took a total of ~13 seconds; 2 of these took less than 3 seconds and the other 2 took more than that.","title":"Histogram"},{"location":"guide/metrics/#summary","text":"The Summary metric is very similar to the histogram, and works the same with Titan (predicate, etc.) except it does not count the observations in each buckets, instead it computes the sum of it. Also these buckets in Summary are called quantiles and must be between zero and one (0 < q < 1).","title":"Summary"},{"location":"guide/metrics/#labels","text":"Labels allow adding granularity to metrics without duplicating them. From the official documentation : CAUTION: Remember that every unique combination of key-value label pairs represents a new time series, which can dramatically increase the amount of data stored. Do not use labels to store dimensions with high cardinality (many different label values), such as user IDs, email addresses, or other unbounded sets of values. Say for instance you have a small API with three endpoints and simply want to track the number of times they get pinged. Though you could create three separate Counters it might be more convenient to create a simple Counter with a label that can be set to the path that is used. c <- Counter$new( name = \"api_visits_total\", help = \"Total API visits\", labels = \"endpoint\" ) c$inc(1, endpoint = \"/\") c$inc(1, endpoint = \"/count\") c$inc(1, endpoint = \"/home\") c$inc(2, endpoint = \"/home\") previewMetrics() # HELP api_visits_total Total API visits # TYPE api_visits_total counter api_visits_total {endpoint=\"/\"} 1 api_visits_total {endpoint=\"/count\"} 1 api_visits_total {endpoint=\"/home\"} 3 If you use labels you must specify all of the labels every time you change the value of the metric ( inc , dec , set , observe ). Otherwise titan throws a warning and ignores the action.","title":"Labels"},{"location":"guide/shiny/","text":"Shiny Basics In this wee vignette we give just basic examples of how to use titan in shiny applications. Counter Below is a very basic shiny application that simply logs clicks of a button. library(shiny) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { cat(\"Logging one click\\n\") }) } shinyApp(ui, server) Let's use titan to track the number of clicks on this button. We can use a counter since the number of clicks can only increase over time. Load the titan package then create the counter. Note that it is created outside the application, as it only needs to be created once, placing it in the server would recreate it every time. Though this should not be an issue as titan prevents you from overwriting an already created counter it is best to avoid it. In the observer we increment the counter, then note that we launch the application with titanApp and not shinyApp , it works the exact same way but exposes the metrics. library(titan) library(shiny) # create the counter c <- Counter$new( name = \"btn_click_total\", help = \"Number of clicks of the button\" ) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { c$inc() cat(\"Logging one click\\n\") }) } # use titanApp titanApp(ui, server) Histogram We can also use a histogram to track the performances of a particularly long request. Say for instance, that the application, at the click of a button, makes a relatively large request to a database or runs a time consuming model, surely we'd like to track that. We can build a histogram to track the time it takes to run that process. We'll use the histogram to put the time it takes into three bins: Less than 3 seconds Between 3 and 6 seconds 6 Seconds and more library(titan) library(shiny) classify <- function(value){ v <- as.numeric(value) if(v < 3) return(bucket(\"0-3\", v)) else if (v > 3 && v < 6) return(bucket(\"3-6\", v)) else return(bucket(\"9\", v)) } hist <- Histogram$new( \"process_time\", \"Lengthy process timing\", predicate = classify ) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { start <- Sys.time() on.exit({ diff <- Sys.time() - start hist$observe(diff) }) Sys.sleep(sample(1:9, 1)) cat(\"Logging one click\\n\") }) } titanApp(ui, server) Visits","title":"Shiny"},{"location":"guide/shiny/#shiny-basics","text":"In this wee vignette we give just basic examples of how to use titan in shiny applications.","title":"Shiny Basics"},{"location":"guide/shiny/#counter","text":"Below is a very basic shiny application that simply logs clicks of a button. library(shiny) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { cat(\"Logging one click\\n\") }) } shinyApp(ui, server) Let's use titan to track the number of clicks on this button. We can use a counter since the number of clicks can only increase over time. Load the titan package then create the counter. Note that it is created outside the application, as it only needs to be created once, placing it in the server would recreate it every time. Though this should not be an issue as titan prevents you from overwriting an already created counter it is best to avoid it. In the observer we increment the counter, then note that we launch the application with titanApp and not shinyApp , it works the exact same way but exposes the metrics. library(titan) library(shiny) # create the counter c <- Counter$new( name = \"btn_click_total\", help = \"Number of clicks of the button\" ) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { c$inc() cat(\"Logging one click\\n\") }) } # use titanApp titanApp(ui, server)","title":"Counter"},{"location":"guide/shiny/#histogram","text":"We can also use a histogram to track the performances of a particularly long request. Say for instance, that the application, at the click of a button, makes a relatively large request to a database or runs a time consuming model, surely we'd like to track that. We can build a histogram to track the time it takes to run that process. We'll use the histogram to put the time it takes into three bins: Less than 3 seconds Between 3 and 6 seconds 6 Seconds and more library(titan) library(shiny) classify <- function(value){ v <- as.numeric(value) if(v < 3) return(bucket(\"0-3\", v)) else if (v > 3 && v < 6) return(bucket(\"3-6\", v)) else return(bucket(\"9\", v)) } hist <- Histogram$new( \"process_time\", \"Lengthy process timing\", predicate = classify ) ui <- fluidPage( actionButton(\"click\", \"click me!\") ) server <- function(input, output){ observeEvent(input$click, { start <- Sys.time() on.exit({ diff <- Sys.time() - start hist$observe(diff) }) Sys.sleep(sample(1:9, 1)) cat(\"Logging one click\\n\") }) } titanApp(ui, server)","title":"Histogram"},{"location":"guide/shiny/#visits","text":"","title":"Visits"}]}